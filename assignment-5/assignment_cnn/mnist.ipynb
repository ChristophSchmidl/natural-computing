{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real-world example (MNIST ConvNet)\n",
    "\n",
    "Here, we will train an extremely simple architecture of a convolutional network to classify MNIST digits. Next, you will have to build a more complex architecture to achieve better classification results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/teslah2o/Downloads/assignment_cnn/.env/local/lib/python2.7/site-packages/theano/tensor/signal/downsample.py:6: UserWarning: downsample module has been moved to the theano.tensor.signal.pool module.\n",
      "  \"downsample module has been moved to the theano.tensor.signal.pool module.\")\n"
     ]
    }
   ],
   "source": [
    "import sys,os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "import lasagne\n",
    "import numpy as np\n",
    "from __future__ import print_function\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (5.0, 4.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# ################## Download and prepare the MNIST dataset ##################\n",
    "# This is just some way of getting the MNIST dataset from an online location\n",
    "# and loading it into numpy arrays. It doesn't involve Lasagne at all.\n",
    "\n",
    "def load_dataset():\n",
    "    # We first define a download function, supporting both Python 2 and 3.\n",
    "    if sys.version_info[0] == 2:\n",
    "        from urllib import urlretrieve\n",
    "    else:\n",
    "        from urllib.request import urlretrieve\n",
    "    dataset_path='nc17nn/datasets/'\n",
    "    def download(filename, source='http://yann.lecun.com/exdb/mnist/'):\n",
    "        print(\"Downloading %s\" % filename)\n",
    "        urlretrieve(source + filename, dataset_path + filename)\n",
    "\n",
    "    # We then define functions for loading MNIST images and labels.\n",
    "    # For convenience, they also download the requested files if needed.\n",
    "    import gzip\n",
    "\n",
    "    def load_mnist_images(filename):\n",
    "        if not os.path.exists(dataset_path + filename):\n",
    "            download(filename=filename)\n",
    "        # Read the inputs in Yann LeCun's binary format.\n",
    "        with gzip.open(dataset_path + filename, 'rb') as f:\n",
    "            data = np.frombuffer(f.read(), np.uint8, offset=16)\n",
    "        # The inputs are vectors now, we reshape them to monochrome 2D images,\n",
    "        # following the shape convention: (examples, channels, rows, columns)\n",
    "        data = data.reshape(-1, 1, 28, 28)\n",
    "        # The inputs come as bytes, we convert them to float32 in range [0,1].\n",
    "        # (Actually to range [0, 255/256], for compatibility to the version\n",
    "        # provided at http://deeplearning.net/data/mnist/mnist.pkl.gz.)\n",
    "        return data / np.float32(256)\n",
    "\n",
    "    def load_mnist_labels(filename):\n",
    "        if not os.path.exists(dataset_path + filename):\n",
    "            download(filename=filename)\n",
    "        # Read the labels in Yann LeCun's binary format.\n",
    "        with gzip.open(dataset_path + filename, 'rb') as f:\n",
    "            data = np.frombuffer(f.read(), np.uint8, offset=8)\n",
    "        # The labels are vectors of integers now, that's exactly what we want.\n",
    "        return data\n",
    "\n",
    "    # We can now download and read the training and test set images and labels.\n",
    "    X_train = load_mnist_images('train-images-idx3-ubyte.gz')\n",
    "    y_train = load_mnist_labels('train-labels-idx1-ubyte.gz')\n",
    "    X_test = load_mnist_images('t10k-images-idx3-ubyte.gz')\n",
    "    y_test = load_mnist_labels('t10k-labels-idx1-ubyte.gz')\n",
    "\n",
    "    # We reserve the last 10000 training examples for validation.\n",
    "    X_train, X_val = X_train[:-10000], X_train[-10000:]\n",
    "    y_train, y_val = y_train[:-10000], y_train[-10000:]\n",
    "\n",
    "    # We just return all the arrays in order, as expected in main().\n",
    "    # (It doesn't matter how we do this as long as we can read them again.)\n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading train-images-idx3-ubyte.gz\n",
      "Downloading train-labels-idx1-ubyte.gz\n",
      "Downloading t10k-images-idx3-ubyte.gz\n",
      "Downloading t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAEKCAYAAAAy4ujqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngCHCBwwRPmCI8AFD/wNvStUiyku+oQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f5f11d0d810>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# We'll use the load_data function to load our train and test set (this can take a while)\n",
    "X_train, y_train, X_valid, y_valid, X_test, y_test = load_dataset()\n",
    "# Create a dataset dictionary for convenience\n",
    "dataset = {\n",
    "    'train': {'X': X_train, 'y': y_train},\n",
    "    'valid': {'X': X_valid, 'y': y_valid}}\n",
    "# Plot an example digit with its label\n",
    "plt.imshow(dataset['train']['X'][0][0], interpolation='nearest', cmap=plt.cm.gray)\n",
    "plt.title(\"Label: {}\".format(dataset['train']['y'][0]))\n",
    "plt.gca().set_axis_off()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ConvNet Input\n",
    "\n",
    "In `lasagne`, the convention for a 2D convolutional network is that the data's shape throughout the network is `(n_examples, n_channels, width, height)`.  Since MNIST digits has a single channel (they're grayscale images), `n_channels = 1` for the input layer; if we were dealing with RGB images we'd have `n_channels = 3`.  Within the network, `n_channels` is the number of filter kernels of each layer.\n",
    "\n",
    "Conveniently, we can make the first dimension (the \"number of example\" dimension) variable.  This comes in handy when you pass your network training examples in minibatches, but want to evaluate the output on the entire validation or test set.  This is designated by setting the first entry of the shape passed to the `InputLayer` to `None`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We'll determine the input shape from the first example from the training set.\n",
    "input_shape = dataset['train']['X'][0].shape\n",
    "l_in = lasagne.layers.InputLayer(\n",
    "    shape=(None, input_shape[0], input_shape[1], input_shape[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutional layers\n",
    "\n",
    "The basic 2D convolutional layer in Lasagne is `Conv2DLayer`.  This uses Theano's built-in convolution operation to convolve a collection 2D filter against the last two dimensions of its inputs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create the first convolutional layer\n",
    "l_conv1 = lasagne.layers.Conv2DLayer(\n",
    "    l_in,\n",
    "    # Here, we set the number of filters and their size.\n",
    "    num_filters=32, filter_size=(5, 5),\n",
    "    # lasagne.nonlinearities.rectify is the common ReLU nonlinearity\n",
    "    nonlinearity=lasagne.nonlinearities.rectify,\n",
    "    # Use He et. al.'s initialization\n",
    "    W=lasagne.init.HeNormal(gain='relu'))\n",
    "# Other arguments: Convolution type (full, same, or valid) and stride"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pooling layers\n",
    "\n",
    "2D max pooling is straightforward: Use the `MaxPool2DLayer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Here, we do 2x2 max pooling.  The max pooling layer also supports striding\n",
    "l_pool1 = lasagne.layers.MaxPool2DLayer(l_conv1, pool_size=(2, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dense layers\n",
    "\n",
    "We'll be using a single hidden layer and a dense output layer.  As is the convention in convnets, the hidden layer will use a ReLU nonlinearity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "l_hidden1 = lasagne.layers.DenseLayer(\n",
    "    l_pool1, num_units=256, \n",
    "    nonlinearity=lasagne.nonlinearities.rectify,\n",
    "    W=lasagne.init.HeNormal(gain='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropout\n",
    "\n",
    "Dropout in Lasagne is implemented as a `Layer` subclass.  By placing a `DropoutLayer` between layers, the connections between the two layers will randomly be dropped.  As we'll see later, setting `get_output` or `get_loss`'s keyword argument `deterministic` to `True` will make the `DropoutLayer` act as a simple pass-through, which is useful when computing the output of the network after training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# p is the dropout probability\n",
    "l_hidden1_dropout = lasagne.layers.DropoutLayer(l_hidden1, p=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "l_output = lasagne.layers.DenseLayer(\n",
    "    l_hidden1_dropout,\n",
    "    # The number of units in the softmax output layer is the number of classes.\n",
    "    num_units=10,\n",
    "    nonlinearity=lasagne.nonlinearities.softmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objectives, updates, and training\n",
    "\n",
    "This part of the code will look very similar to above - we'll define an objective, compute some updates, use the updates to compile Theano functions, then use the functions to train the network and compute its output given some input.  Since this problem is a little harder than our toy example, we'll use ADADELTA, a fancier stochastic optimization technique, described in [ADADELTA: An Adaptive Learning Rate Method](http://arxiv.org/abs/1212.5701).  There's plenty of others to choose from in `lasagne.updates`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "net_output = lasagne.layers.get_output(l_output)\n",
    "true_output = T.ivector('true_output')\n",
    "loss = T.mean(lasagne.objectives.categorical_crossentropy(net_output, true_output))\n",
    "\n",
    "# As mentioned above, when using dropout we should define different losses:\n",
    "# One for training, one for evaluation.  The training loss should apply dropout,\n",
    "# while the evaluation loss shouldn't.  This is controlled by setting get_output's deterministic kwarg.\n",
    "loss_train = T.mean(lasagne.objectives.categorical_crossentropy(\n",
    "        lasagne.layers.get_output(l_output, deterministic=False), true_output))\n",
    "loss_eval = T.mean(lasagne.objectives.categorical_crossentropy(\n",
    "        lasagne.layers.get_output(l_output, deterministic=True), true_output))\n",
    "\n",
    "all_params = lasagne.layers.get_all_params(l_output)\n",
    "# Use ADADELTA for updates\n",
    "updates = lasagne.updates.adadelta(loss_train, all_params)\n",
    "train = theano.function([l_in.input_var, true_output], loss_train, updates=updates)\n",
    "\n",
    "# This is the function we'll use to compute the network's output given an input\n",
    "# (e.g., for computing accuracy).  Again, we don't want to apply dropout here\n",
    "# so we set the deterministic kwarg to True.\n",
    "get_output = theano.function([l_in.input_var],\n",
    "                             lasagne.layers.get_output(l_output, deterministic=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train_cnn():\n",
    "    # Now, let's train it!  We'll chop the training data into mini-batches,\n",
    "    # and compute the validation accuracy every epoch.\n",
    "    BATCH_SIZE = 100\n",
    "    N_EPOCHS = 10\n",
    "    # Keep track of which batch we're training with\n",
    "    batch_idx = 0\n",
    "    # Keep track of which epoch we're on\n",
    "    epoch = 0\n",
    "    while epoch < N_EPOCHS:\n",
    "        # Extract the training data/label batch and update the parameters with it\n",
    "        train(dataset['train']['X'][batch_idx:batch_idx + BATCH_SIZE],\n",
    "              dataset['train']['y'][batch_idx:batch_idx + BATCH_SIZE])\n",
    "        batch_idx += BATCH_SIZE\n",
    "        # Once we've trained on the entire training set...\n",
    "        if batch_idx >= dataset['train']['X'].shape[0]:\n",
    "            # Reset the batch index\n",
    "            batch_idx = 0\n",
    "            # Update the number of epochs trained\n",
    "            epoch += 1\n",
    "            # Compute the network's output on the validation data\n",
    "            val_output = get_output(dataset['valid']['X'])\n",
    "            # The predicted class is just the index of the largest probability in the output\n",
    "            val_predictions = np.argmax(val_output, axis=1)\n",
    "            # The accuracy is the average number of correct predictions\n",
    "            accuracy = np.mean(val_predictions == dataset['valid']['y'])\n",
    "            print(\"Epoch {} validation accuracy: {}\".format(epoch, accuracy))\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 validation accuracy: 0.9805\n",
      "Epoch 2 validation accuracy: 0.9845\n",
      "Epoch 3 validation accuracy: 0.9864\n",
      "Epoch 4 validation accuracy: 0.987\n",
      "Epoch 5 validation accuracy: 0.9881\n",
      "Epoch 6 validation accuracy: 0.9875\n",
      "Epoch 7 validation accuracy: 0.9866\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-30cb6c65e5ac>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Train and evaluate the simple CNN\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0maccuracy_simple_cnn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_cnn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-18-ded9992845b2>\u001b[0m in \u001b[0;36mtrain_cnn\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[1;31m# Extract the training data/label batch and update the parameters with it\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         train(dataset['train']['X'][batch_idx:batch_idx + BATCH_SIZE],\n\u001b[1;32m---> 13\u001b[1;33m               dataset['train']['y'][batch_idx:batch_idx + BATCH_SIZE])\n\u001b[0m\u001b[0;32m     14\u001b[0m         \u001b[0mbatch_idx\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[1;31m# Once we've trained on the entire training set...\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/teslah2o/Downloads/assignment_cnn/.env/local/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    857\u001b[0m         \u001b[0mt0_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    858\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 859\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    860\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'position_of_error'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Train and evaluate the simple CNN\n",
    "accuracy_simple_cnn=train_cnn()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a more complex architecture \n",
    "\n",
    "Now that you trained a simple CNN it is time for you to build a more complex architecture to achieve higher validation accuracy. You can use all the techniques you learned from the course: for their implementation in Lasagne take a look at library references at http://lasagne.readthedocs.io/en/latest/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Build your network \n",
    "input_shape = dataset['train']['X'][0].shape\n",
    "l_in = lasagne.layers.InputLayer(\n",
    "    shape=(None, input_shape[0], input_shape[1], input_shape[2]))\n",
    "l_conv1 = lasagne.layers.Conv2DLayer(\n",
    "    l_in,\n",
    "    num_filters=32, filter_size=(5, 5),\n",
    "    nonlinearity=lasagne.nonlinearities.rectify,\n",
    "    W=lasagne.init.HeNormal(gain='relu'))\n",
    "\n",
    "l_pool1 = lasagne.layers.MaxPool2DLayer(l_conv1, pool_size=(2, 2))\n",
    "#######################################################################################\n",
    "#TODO add your layers\n",
    "#######################################################################################\n",
    "\n",
    "l_output = lasagne.layers.DenseLayer(\n",
    "    l_last,\n",
    "    num_units=10,\n",
    "    nonlinearity=lasagne.nonlinearities.softmax)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Train and evaluate your network\n",
    "net_output = lasagne.layers.get_output(l_output)\n",
    "accuracy_customized_cnn=train_cnn()\n",
    "print(\"Your network achieves {} of validation accuracy improvement\".format(accuracy_customized_cnn-accuracy_simple_cnn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

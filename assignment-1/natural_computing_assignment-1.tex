\documentclass[a4paper]{article}

\usepackage[english]{babel}
\usepackage{amsmath}
\usepackage{float}
\usepackage{amssymb}
\usepackage{dsfont}
\usepackage{graphicx}
\usepackage{listings}
\usepackage[hyphens]{url}
\usepackage{titling}
\usepackage{varwidth}
\usepackage{hyperref}
\usepackage{color} %red, green, blue, yellow, cyan, magenta, black, white
\definecolor{mygreen}{RGB}{28,172,0} % color values Red, Green, Blue
\definecolor{mylilas}{RGB}{170,55,241}



\usepackage{geometry}
 \geometry{
 a4paper,
 total={165mm,257mm},
 left=20mm,
 top=20mm,
 }

\title{Natural Computing\\Assignment 1}
\author{
  Christoph Schmidl\\ s4226887\\      \texttt{c.schmidl@student.ru.nl}
  \and
  Koen Vijverberg\\ s1337\\     \texttt{koen@example.com}
  \and
  Alex\\	s4125304\\	\texttt{alex.kolmus@student.ru.nl}
}
\date{\today}

\begin{document}
\maketitle


\subsection*{Exercises on Evolutionary Computation}

\begin{enumerate}

	% Task 1	
	\item A generational GA has a population size of 100 individuals; uses fitness proportional
selection without elitisms; and after $t$ generation has a mean population fitness of 76.
There is one copy of the current best member, which has fitness 157.

	\begin{enumerate}
		\item What is the expectation for the number of copies of the best individual in the mating pool?\\
		\textbf{Solution:}
		
\begin{align*}
	\text{Pop\_size} &= 100\notag\\
	\text{t generations} \rightarrow \text{mean fitness} &= 76\notag\\
	P(best) = \frac{157}{76 \cdot 100} &\approx 0.0207\notag\\
	100 \cdot P(best) &\approx 2.07\notag
\end{align*}	
		
		
		\item What is the probability that there will be no copies of the best individual in the mating pool?\\
		\textbf{Solution:}
		
\begin{align*}
 P(\text{not\_best}) = 1 - P(best) &\approx 0.9793\notag\\
 100 \cdot P(\text{not\_best}) &\approx 97.93
\end{align*}		
		
	

	
	
	\end{enumerate}

	% Task 2	
	\item Given the fitness function $f(x) = x^2$, calculate the probability of selecting the individuals $x = 3, x = 5$ and $x = 7$, using roulette wheel selection. Calculate the probability of selecting the same individuals when the fitness function is $f1(x) = f(x) + 8$. Which fitness function yields a lower selection pressure?\\
	\textbf{Solution:}\\	


\begin{table}[H]
\centering
\begin{tabular}{|c|c|c|}
\hline
\textbf{Function:} & $f$  & $f_1$ \\ \hline
$x = 3$ & $x^2 = 9$ & $x^2 + 8 = 17$ \\ \hline
$x = 5$ & $x^2 = 25$ & $x^2 + 8 = 33$ \\ \hline
$x = 7$ & $x^2 = 49$ & $x^2 + 8 = 57$ \\ \hline
\textbf{Sum:} & 83 & 107 \\ \hline
\end{tabular}
\end{table}


\textbf{Probabilities for x squared:}	
	
\begin{align*}
P(x = 3) &= \frac{9}{83} \approx 0.11\notag\\
P(x = 5) &= \frac{25}{83} \approx 0.30\notag\\
P(x = 7) &= \frac{49}{83} \approx 0.59\notag
\end{align*}	
	
\textbf{Probabilities for x squared plus eight:}	

\begin{align*}
P(x = 3) &= \frac{17}{107} \approx 0.16\notag\\
P(x = 5) &= \frac{33}{107} \approx 0.33\notag\\
P(x = 7) &= \frac{57}{107} \approx 0.53\notag
\end{align*}	

Function $f_1$ has a lower selection pressure, fitter individuals have a lower probability of getting selected.\\

	% Task 3
	\item The Counting Ones problem amounts to find a bit string whose sum of its entries is maximum. This easy problem is used to illustrate the difference between Monte-Carlo search and a simple genetic algorithm.\\
	Monte-Carlo search for binary problems works as follows.
	
	\begin{enumerate}
		\item Start with a random bit sequence.
		\item If it is equal to the goal sequence then stop, otherwise repeat the process from step (a).
	\end{enumerate}
	
	Implement a Monte-Carlo search algorithm for the Counting Ones problem. Let the input take the following arguments:
	
	\begin{itemize}
		\item the objective function
		\item the length $n$ of the bitstrings
		\item the maximum number of fitness function evaluations
\end{itemize}

Let the algorithm produce as outputs:

\begin{itemize}
	\item the best individual found by the algorithm
	\item the fitness of the best individual
\end{itemize}

\begin{enumerate}
	\item Use $n = 100$ and for a run of 1500 iterations, plot the best fitness against the elapsed number of iterations.\\
	\textbf{Solution:}\\
	
The code regarding this exercise can be found at our Git Repository:

\begin{itemize}
	\item Jupyther Notebook file: \url{https://github.com/ChristophSchmidl/natural-computing/blob/master/assignment-1/Monte_Carlo_Search_Counting_Ones.ipynb}
	\item Pure Python file: \url{https://github.com/ChristophSchmidl/natural-computing/blob/master/assignment-1/Monte_Carlo_Search_Counting_Ones.py}
\end{itemize}	
	
	\begin{figure}[H]
	\centering
  	\includegraphics[width=0.8\textwidth]{images/monte_carlo_1500_iterations.png}
	\end{figure}	
	
	
	\item Now do ten runs. How many times the algorithm finds the optimum? Almost never.\\
	\textbf{Solution:}\\
	
	\begin{figure}[H]
	\centering
  	\includegraphics[width=0.8\textwidth]{images/monte_carlo_10_iterations.png}
	\end{figure}	
	
	
	
\end{enumerate}			
	
	% Task 4
	\item A simple (1 + 1)-GA for binary problems works as follows.
	
		\begin{enumerate}
			\item Randomly generate a bit sequence $x$
			\item Create a copy of $x$ and invert each of its bits with probability $p$. Let $x_m$ be the result.
			\item If $x_m$ is closer to the goal sequence than $x$ then replace $x$ with $x_m$
			\item Repeat the process from step (b) with the new $x$ until the goal sequence is reached.
		\end{enumerate}

	Implement a simple (1 + 1)-GA for solving the Counting Ones problem, using the same approach as with the Monte-Carlo search algorithm.
	
	\begin{enumerate}
		\item Use $n = 100$ and a mutation rate $p = 1/n$. For a run of 1500 iterations, plot the best fitness against the elapsed number of iterations.\\
		\textbf{Solution:}\\
		
The code regarding this exercise can be found at our Git Repository:

\begin{itemize}
	\item Jupyther Notebook file: \url{https://github.com/ChristophSchmidl/natural-computing/blob/master/assignment-1/Genetic_Algorithm_Counting_Ones.ipynb}
	\item Pure Python file: \url{https://github.com/ChristophSchmidl/natural-computing/blob/master/assignment-1/Genetic_Algorithm_Counting_Ones.py}
\end{itemize}			
		
	\begin{figure}[H]
	\centering
  	\includegraphics[width=0.8\textwidth]{images/GA_1500_iterations.png}
	\end{figure}
		
		
		\item Now do ten runs. How many times the algorithm finds the optimum?\\
		\textbf{Solution:}\\
		
	\begin{figure}[H]
	\centering
  	\includegraphics[width=0.8\textwidth]{images/GA_10_iterations.png}
	\end{figure}		
		
		
		
		\item Is there a difference in performance compared to the Monte-Carlo Search algorithm? Justify your answer.\\
		\textbf{Solution:}\\

Yes, the performance of the (1+1)-GA approach is performing much better than the monte carlo approach and converges faster to the optimal solution. The probability of each bit in the monte carlo approach is set to 0.5. If the optimal fitness value is set to 100, then the average solution is expected to be around 50 as we can observe in exercise 3. Because the (1+1)GA-approach starts with a random sequence and then sets the probability of flipping a bit to $\frac{1}{100}$ in this case, the resulting mutated bitsequences are less random. By keeping the mutated bitsequence with the best fitness in each iteration and only mutating bits with a probability of 1 out of 100, this approach performs better when the amount of iterations is relatively high. If the amount of iterations is low, then the performance boost of the GA-approach is not significant.		
		
	\end{enumerate}
	
	
	% Task 5
	\item (Genetic Programming) Give a suitable function, terminal set and s-expression for the following logical formula:
	
	\begin{equation}
		(x \wedge true) \rightarrow ((x \vee y) \vee (z \leftrightarrow (x \wedge y))) \notag
	\end{equation}
	\textbf{Solution:}\\

	Function set: $\{\vee,\wedge,\rightarrow,\leftrightarrow\}$\\
	Terminal set: $\{x,y,z,true,(false)\}$
	\begin{figure}[ht!]
	\centering
  	\includegraphics[width=0.6\textwidth]{images/s-expression.png}
	\end{figure}

	% Task 6
	\item (Genetic Programming) Implement a GP program for finding a symbolic expression that fits the following data:

	\begin{figure}[ht!]
	\centering
  	\includegraphics[width=0.35\textwidth]{images/table.PNG}
	\end{figure}	

with the following paramter setting:
\begin{itemize}
	\item population size: 1000
	\item function set: $\{+,-,*,log,exp,sin,cos,div \}$
	\item terminal set: $x$
	\item initialization: full
	\item number of generations: 50
	\item crossover probability: 0.7
	\item mutation probability: 0
	\item fitness: - sum of absolute errors
\end{itemize}

You can use an existing GP framework: see for instance list of implementation frameworks mentioned in the syllabus.\\

Plot the following:

\begin{enumerate}
	\item best of generatation fitness (y-axis) versus generation (x-axis)\\
	\textbf{Solution:}\\
	\begin{figure}[ht!]
	\centering
  	\includegraphics[width=0.5\textwidth]{SR_fit.png}
	\end{figure}
	
	\item best of generation size (y-axis) versus generation (x-axis).\\
	\textbf{Solution:}\\
	\begin{figure}[ht!]
	\centering
  	\includegraphics[width=0.5\textwidth]{SR_sz.png}
	\end{figure}
	
\end{enumerate}

Can you observe any undesirable phenomenon from these plots? In case of positive answer, explain how you would try to overcome the corresponding problem (you can refer to the literature).\\
\textbf{Solution:}\\
The size keeps increasing. It seems that the algorithm is overfitting a 'wrong' solution by adding extra terms such that it fits the data. A possible countermeasure is to incorporate the size of the tree into the fitness and punish large trees.

The code regarding this exercise can be found at our Git Repository:

\begin{itemize}
	\item Pure Python file: \url{https://github.com/ChristophSchmidl/natural-computing/blob/master/assignment-1/Symb_reg.py}
\end{itemize}	
		

\end{enumerate}




\end{document}

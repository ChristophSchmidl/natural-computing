\documentclass[a4paper]{article}

\usepackage[english]{babel}
\usepackage{amsmath}
\usepackage{float}
\usepackage{amssymb}
\usepackage{dsfont}
\usepackage{graphicx}
\usepackage{listings}
\usepackage[hyphens]{url}
\usepackage{titling}
\usepackage{varwidth}
\usepackage{hyperref}
\usepackage{url}
\usepackage{color} %red, green, blue, yellow, cyan, magenta, black, white
\definecolor{mygreen}{RGB}{28,172,0} % color values Red, Green, Blue
\definecolor{mylilas}{RGB}{170,55,241}


\usepackage{geometry}
 \geometry{
 a4paper,
 total={165mm,257mm},
 left=20mm,
 top=20mm,
 }

\title{Natural Computing\\Assignment 3}
\author{
  Christoph Schmidl\\ s4226887\\      \texttt{c.schmidl@student.ru.nl}
  \and
  Koen Vijverberg\\ s4132858\\     \texttt{koen.vijverberg@student.ru.nl}
  \and
  Alex Kolmus\\	s4125304\\	\texttt{alex.kolmus@student.ru.nl}
}
\date{\today}

\begin{document}
\maketitle


\subsection*{Swarm Intelligence}

\begin{enumerate}

	% Task 1	
	\item Consider an illustrative example of a PSO system composed of three particles. Consider the following update rule for each particle $i$ and dimension $d$:
	
	\begin{equation}
		v(i;d) = wv(i;d) + r_1(x^*(i;d) - x(i;d)) + r_2(x^*(d) - x(i;d)) \notag
	\end{equation}

To facilitate calculation, we will ignore the fact that $r_1$ and $r_2$ are random numbers and fix them to 0.5 for this exercise. The space of solutions is the two dimensional real values space and the current state of the swarm is as follows

\begin{itemize}
	\item Position of particles: $x_1 = (5,5); x_2 = (8,3); x_3 = (6,7)$
	\item Individual best positions: $x^*_1 = (5,5); x^*_2 = (7,3); x^*_3 = (5,6)$
	\item Social best position: $x^* = (5,5)$
	\item Velocities: $v_1 = (2,2); v_2 = (3,3); v_3 = (4,4)$
\end{itemize}

\begin{enumerate}
	% 1a)
	\item What would be the next position of each particle after one iteration of the PSO algorithm with $w = 2$?\\
	\textbf{Solution:}
	\begin{align*}
	    x(i, 2) = x(i, 1) + v(i, 1)
	\end{align*}
	\begin{align*}
	\text{for $i = 1$ we obtain:}\\
	    v(1,1) &= w(2,2) + r_1((5,5) - (5,5)) + r_2((5,5) - (5,5))\\
	           &= (2w,2w) \rightarrow (4,4)\\
	   x(1,2) &= (5,5) + (4,4) = (9,9)\\
	\text{for $i = 2$ we obtain:}\\
	    v(2,1) &= w(3,3) + r_1((7,3) - (8,3)) + r_2((5,5) - (8,3))\\
	           &= (3w,3w) + r_1(-1,0) + r_2(-3, 2) = (3w - r_1 - 3r_2, 3w + 2r_2) \rightarrow (4, 7)\\
	   x(2,2) &= (8,3) + (4,7) = (12, 11)\\
	\text{for $i = 3$ we obtain:}\\
	    v(3,1) &= w(4,4) + r_1((5,6) - (6,7)) + r_2((5,5) - (6,7))\\
	           &= (4w,4w) + r_1(-1,-1) + r_2(-1, -2) = (4w - r_1 - r_2, 4w - r_1 - 2r_2) \rightarrow (7, 6.5)\\
	   x(3,2) &= (6,7) + (7, 6.5) = (13, 13.5)
	\end{align*}
	
	
	% 1b)
	\item And using $w = 0.1$?\\
	\textbf{Solution:}\\
	Using the analytical solutions of the previous exercise we obtain for $w = 0.1$ the following solutions:
	\begin{align*}
	    \text{for $i = 1$ we obtain:}\\
	    v(1,1) &= (2w, 2w) \rightarrow (0.2, 0.2)\\
	    x(1,2) &= (5,5) + (0.2, 0.2) = (5.2, 5.2)\\
	    \text{for $i = 2$ we obtain:}\\
	    v(2,1) &= (3w - r_1 - 3r_2, 3w + 2r_2) \rightarrow (-1.2, 1.3)\\
	    x(2,2) &= (8,3) + (-1.2, 1.3) = (6.8, 4.3)
	    \text{for $i = 3$ we obtain:}\\
	    v(3,1) &= (4w - r_1 - r_2, 4w - r_1 - 2r_2) \rightarrow (-0.6, -1.1)
	    x(3,2) &= (6,7) + (-0.6
	\end{align*}
	% 1c)
	\item Explain what is the effect of the parameter $w$.\\
	\textbf{Solution:}\\
	$w$ can be viewed as a `momentum' hyperparameter, it carries a factor (can be larger than 1) of the previous velocity into the next time step. So what are its effects? Lets focus on extremes, for $w = 0$ the swarm only takes 'local' information into account and is only busy with finding a local optimum (which might be the global optimum). For $w >> 1$ it almost completely ignores the local information and explores the solution space.\bigskip
	
	So small $w$ are focused on exploitation, while large $w$ are focused on exploration.
	
	% 1d)
	\item Give an advantage and a disadvantage of a high value of $w$.\\
	\textbf{Solution:}\\
	\begin{enumerate}
	    \item[Advantage] A large $w$ allows us to explore other local minimum and thus possibly finding a better solution.
	    \item[Disadvantage] A large $w$ can prevent a solution from converging and thus having a very suboptimal end solution.
	\end{enumerate}
	
\end{enumerate}

	% Task 2
	\item Consider a particle swarm consisting of a single member. How would it perform in a trivial task such as the minimization of $f(x) = x^2$ when $w < 1$?\\
	\textbf{Solution:}\\
	Given that $r_1, r_2 > 0$ it would find a solution. Since $f(x)$ establishes a convex solution space the local information is enough to find the minimum (since local = global for convex spaces). What would happen would be somewhat similar to gradient descent with momentum ($<1$), it will be damped oscillator that eventually stops in the minimum.
	
	% Task 3
	\item The figure shows an example from the ACO book by Dorigo and Stuetzle. What results do you expect for ant colony algorithm that does not use tabu lists (except for inhibition of immediate return to the previous node)?
	
		\begin{figure}[H]
	    \centering
  	    \includegraphics[width=0.4\textwidth]{images/task3.PNG}
	    \end{figure}	
	
	
	\textbf{Solution:}\\
	There are cycles possible in the bottom half of the graph that would make that route seem larger than the route through the top of the graph. I would expect that the (early) convergence would be that the ant colony takes the route trough the upper nodes and edges of the graph. After a lot of iterations it might find the fastest route through the bottom half of the graph (down, up, right, down, up).
	
	% Task 4
	\item Assume that ants are allowed to lay pheromone on a path at every time step, so that pheromone update rule is applied at each time step. Come up with a combination local/global updating scheme that encourages exploration and exploitation - consider which parameters influence this.\\
	\textbf{Solution:}\\
	A exploration solution might be that you keep track of a \%$global\_pheromone$\% parameter at each edge of the graph, copy that for each ant when it is at the source/start node to a \%$local\_pheromone$\% parameter which gets lowered as you travel down an edge to prevent re-taking routes. At edge intersections choose a path with a probability proportional to the amount of pheromone on it (and prevent re-tracing its previous step). As soon as you reach destination update the \%$global pheromone$\% proportional to the length of the path taken. Set minimum and maximum levels of pheromone to enable exploration.


	% Task 5
	\item The goal of this exercise is to practice with an implementation of ACO, so please do not use other (possible better) methods for solving this problem.
	
	\begin{enumerate}
		% 5a)
		\item Code an ACO to solve Sudoku's. First, you need to think how to represent Sudoku: there are three conditions an optimal solution must fulfill, each line must contain all integers $\{1,2,3,4,5,6,7,8,9 \}$ once and only once, the same applies to columns and 3x3 subgrids. You can fix one of them so that you will prevent violations. The ACO will have 9x9x9 pheromone matrix, where you update pheromones for the values appearing in the best solutions inversely proportionally to the fitness value. You have to consider also how the old pheromones will fade.\\
		\textbf{Solution:}\\
		
		The code regarding this exercise can be found at our Git Repository:\\
		\url{https://github.com/ChristophSchmidl/natural-computing/tree/master/assignment-3/sudoku_aco}\\
	
	    This exercise has been constructed in Python 3.5 in an object-oriented way. The main file to start the program and construct the benchmark-figures is \texttt{sudoku\_aco.py} The utility file \texttt{sudoku\_utils.py} is responsible for parsing the given txt-files and enforcing the rules of Sudoku. The AntColony class and Ant class are mainly responsible for executing the ACO algorithm. Both files can be found in the folder \texttt{single\_threaded}. We also tried to begin to program this exercise in a multi threaded manner because this algorithm can exploit parallelism in an extensive way but we did not manage to finish it in time.\\
		
		
		% 5b)
		\item Consider the benchmark Sudoku problems are available at \url{http://lipas.uwasa.fi/~timan/sudoku/}. Run your ACO on the following benchmark instances \textsf{10a.txt, s10b.txt, s11a.txt, s11b.txt}. Report and discuss the results.\\
		 \textbf{Solution:}\\
		
		The benchmarks have been performed with the following parameters:
		
		\begin{itemize}
		    \item Number of ants: 700
		    \item Number of steps: 20
		    \item Alpha (importance of pheromone trail): 1
		    \item Beta: values between 0 and 2 
		    \item Rho (evaporation): 0.002
		\end{itemize}
		
		The focus of this benchmark has been a varying beta value which is a variation in importance of the heuristic value. The heuristic value gives information in how far an ant should choose a possible digit at a certain location based on a certain probability. By giving alpha a fixed value and let beta vary between value below and above alpha, we should expect different decision behaviours. These behaviours should vary between favouring pheromone trails, equal decisions and favouring heuristic values and therefore let ants more choose by randomness.
		
		% s10a
    	\begin{figure}[H]
        	\centering
          	\includegraphics[width=0.8\textwidth]{images/average_s10a.png}
    	\end{figure}	
    	
    	\begin{figure}[H]
        	\centering
          	\includegraphics[width=0.8\textwidth]{images/best_s10a.png}
    	\end{figure}
    	
    	% s10b
    	    	\begin{figure}[H]
        	\centering
          	\includegraphics[width=0.8\textwidth]{images/average_s10b.png}
    	\end{figure}	
    	
    	\begin{figure}[H]
        	\centering
          	\includegraphics[width=0.8\textwidth]{images/best_s10b.png}
    	\end{figure}
    	
    	% s11a
    	    	\begin{figure}[H]
        	\centering
          	\includegraphics[width=0.8\textwidth]{images/average_s11a.png}
    	\end{figure}	
    	
    	\begin{figure}[H]
        	\centering
          	\includegraphics[width=0.8\textwidth]{images/best_s11a.png}
    	\end{figure}
    	
    	% s11b
    	    	\begin{figure}[H]
        	\centering
          	\includegraphics[width=0.8\textwidth]{images/average_s11b.png}
    	\end{figure}	
    	
    	\begin{figure}[H]
        	\centering
          	\includegraphics[width=0.8\textwidth]{images/best_s11b.png}
    	\end{figure}
		
		As we can see, the graphs strive against the possible optimal score of 81, which represents the score of a solved sudoku puzzle. It seems strange that the average score for all beta values is around 70 although the average score for low beta values should look different. A low beta value should lead to a more intensive incorporation of pheromone trails and therefore different averaged scores. As we look at the best scores, we can see that the algorithm rarely reaches the optimal value of 81 but that a beta value around 1.5 seems to give the best solutions so far.\\
		Our program does not seem to give a quick solution to a sudoku puzzle and the average score graphs seem to give the impression that the ants are not considering the pheromone trails. We would have to inspect all paramters like number of ants, number of steps, evaporation rate and alpha/beta more thoroughly to give clearer insights on these findings.
		
		
	\end{enumerate}
	
\end{enumerate}




\end{document}